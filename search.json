[
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Data Cleaning: Exercises",
    "section": "",
    "text": "Recommended: Complete these exercises in the dedicated Posit Cloud work space, which comes with\n\nall packages pre-installed, and\nan Rmarkdown document to fill in.\n\nIt will be helpful to peek here to verify that your tables generated in Posit Cloud match the desired output (or even to peek at the Code Solution if your cleaned tables don‚Äôt look right).\nClick here to enter the R/Medicine Posit cloud work space\nOtherwise: Follow along this document, work on your personal computer, and challenge yourself not to peek at the code solutions until you have completed the exercise."
  },
  {
    "objectID": "exercises.html#cl1",
    "href": "exercises.html#cl1",
    "title": "Data Cleaning: Exercises",
    "section": "CL1",
    "text": "CL1"
  },
  {
    "objectID": "exercises.html#cl2",
    "href": "exercises.html#cl2",
    "title": "Data Cleaning: Exercises",
    "section": "CL2",
    "text": "CL2"
  },
  {
    "objectID": "exercises.html#set-up",
    "href": "exercises.html#set-up",
    "title": "Data Cleaning: Exercises",
    "section": "Set up",
    "text": "Set up\n\n# import raw data\ndf_raw &lt;- read_excel(\n  path = here(\"data\", \"messy_uc.xlsx\"),\n  sheet = \"Data\",\n  skip = 5\n)\n\n# do initial cleaning of variable names and removing empty rows/columns\ndf_clean &lt;- df_raw |&gt; \n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\"))"
  },
  {
    "objectID": "exercises.html#sp1",
    "href": "exercises.html#sp1",
    "title": "Data Cleaning: Exercises",
    "section": "SP1",
    "text": "SP1\n\nExplore the values of race.\n\n\n\nShow the code solution\ndf_clean |&gt; count(race)\n\n\n# A tibble: 9 √ó 2\n  race                 n\n  &lt;chr&gt;            &lt;int&gt;\n1 African-American     4\n2 AmerInd              1\n3 Asian                1\n4 Caucasian           17\n5 H/API                1\n6 Hawaiian             1\n7 Mixed                1\n8 Other                2\n9 afromerican          2\n\n\n\nIn the df_clean data set, create a new variable named race_clean that cleans the coding of race (combine ‚ÄúAfrican-American‚Äù & ‚Äúafromerican‚Äù; ‚ÄúH/API‚Äù & ‚ÄúMixed‚Äù & ‚ÄúOther‚Äù).\n\n\n\nShow the code solution\ndf_clean &lt;- df_raw |&gt; \n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    race_clean = case_when(\n      race %in% c(\"African-American\", \"afromerican\") ~ \"African-American\",\n      race %in% c(\"H/API\", \"Mixed\", \"Other\") ~ \"Other\",\n      TRUE ~ race\n    )\n  )\n\n\n\nConfirm the new race_clean variable is coded correctly.\n\n\n\nShow the code solution\ndf_clean |&gt; \n  count(race_clean, race)\n\n\n# A tibble: 9 √ó 3\n  race_clean       race                 n\n  &lt;chr&gt;            &lt;chr&gt;            &lt;int&gt;\n1 African-American African-American     4\n2 African-American afromerican          2\n3 AmerInd          AmerInd              1\n4 Asian            Asian                1\n5 Caucasian        Caucasian           17\n6 Hawaiian         Hawaiian             1\n7 Other            H/API                1\n8 Other            Mixed                1\n9 Other            Other                2"
  },
  {
    "objectID": "exercises.html#sp2",
    "href": "exercises.html#sp2",
    "title": "Data Cleaning: Exercises",
    "section": "SP2",
    "text": "SP2\n\nExplore the type of and values of start_plt.\n\n\n\nShow the code solution\ndf_clean |&gt; \n  count(start_plt)\n\n\n# A tibble: 28 √ó 2\n   start_plt        n\n   &lt;chr&gt;        &lt;int&gt;\n 1 115K/microL      1\n 2 1550K/microL     1\n 3 177K/microL      1\n 4 188K/microL      1\n 5 197K/microL      1\n 6 204K/microL      1\n 7 249K/microL      1\n 8 258K/microL      1\n 9 273K/microL      1\n10 288K/microL      1\n# ‚Ñπ 18 more rows\n\n\nShow the code solution\ndf_clean |&gt; \n  select(start_plt) |&gt; \n  glimpse()\n\n\nRows: 30\nColumns: 1\n$ start_plt &lt;chr&gt; \"273K/microL\", \"414K/microL\", \"323K/microL\", \"389K/microL\", ‚Ä¶\n\n\nShow the code solution\ndf_clean[[\"start_plt\"]]\n\n\n [1] \"273K/microL\"  \"414K/microL\"  \"323K/microL\"  \"389K/microL\"  \"411K/microL\" \n [6] \"427K/microL\"  \"249K/microL\"  \"197K/microL\"  \"204K/microL\"  \"305K/microL\" \n[11] \"347K/microL\"  \"402K/microL\"  \"389K/microL\"  \"432K/microL\"  \"288K/microL\" \n[16] \"177K/microL\"  \"290K/microL\"  \"312K/microL\"  \"399K/microL\"  \"423K/microL\" \n[21] \"clumped\"      \"323K/microL\"  \"258K/microL\"  \"115K/microL\"  \"1550K/microL\"\n[26] \"37K/microL\"   \"188K/microL\"  \"456K/microL\"  \"356K/microL\"  \"291K/microL\" \n\n\n\nIn the df_clean data set, create a new variable named start_plt_clean that corrects any unusual values and assigns the correct variable type.\n\n\n\nShow the code solution\ndf_clean &lt;- df_raw |&gt; \n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    race_clean = case_when(\n      race %in% c(\"African-American\", \"afromerican\") ~ \"African-American\",\n      race %in% c(\"H/API\", \"Mixed\", \"Other\") ~ \"Other\",\n      TRUE ~ race\n    ),\n    start_plt_clean = parse_number(start_plt) \n  )\n\n\n\nConfirm the new start_plt_clean variable is coded correctly.\n\n\n\nShow the code solution\ndf_clean |&gt; \n  count(start_plt_clean, start_plt)\n\n\n# A tibble: 28 √ó 3\n   start_plt_clean start_plt       n\n             &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt;\n 1              37 37K/microL      1\n 2             115 115K/microL     1\n 3             177 177K/microL     1\n 4             188 188K/microL     1\n 5             197 197K/microL     1\n 6             204 204K/microL     1\n 7             249 249K/microL     1\n 8             258 258K/microL     1\n 9             273 273K/microL     1\n10             288 288K/microL     1\n# ‚Ñπ 18 more rows\n\n\nShow the code solution\ndf_clean |&gt; \n  select(start_plt, start_plt_clean) |&gt; \n  glimpse()\n\n\nRows: 30\nColumns: 2\n$ start_plt       &lt;chr&gt; \"273K/microL\", \"414K/microL\", \"323K/microL\", \"389K/mic‚Ä¶\n$ start_plt_clean &lt;dbl&gt; 273, 414, 323, 389, 411, 427, 249, 197, 204, 305, 347,‚Ä¶\n\n\nShow the code solution\ndf_clean[[\"start_plt_clean\"]]\n\n\n [1]  273  414  323  389  411  427  249  197  204  305  347  402  389  432  288\n[16]  177  290  312  399  423   NA  323  258  115 1550   37  188  456  356  291\nattr(,\"problems\")\n# A tibble: 1 √ó 4\n    row   col expected actual \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  \n1    21    NA a number clumped"
  },
  {
    "objectID": "exercises.html#sp3",
    "href": "exercises.html#sp3",
    "title": "Data Cleaning: Exercises",
    "section": "SP3",
    "text": "SP3\n\nExplore the type of and values of race_clean.\n\n\n\nShow the code solution\ndf_clean |&gt; \n  count(race_clean)\n\n\n# A tibble: 6 √ó 2\n  race_clean           n\n  &lt;chr&gt;            &lt;int&gt;\n1 African-American     6\n2 AmerInd              1\n3 Asian                1\n4 Caucasian           17\n5 Hawaiian             1\n6 Other                4\n\n\n\nConvert the race_clean variable to a factor such that the most common values present in order in a summary table.\n\n\n\nShow the code solution\ndf_clean &lt;- df_raw |&gt; \n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    race_clean = case_when(\n      race %in% c(\"African-American\", \"afromerican\") ~ \"African-American\",\n      race %in% c(\"H/API\", \"Mixed\", \"Other\") ~ \"Other\",\n      TRUE ~ race\n    ) |&gt; fct_infreq(),\n    start_plt_clean = parse_number(start_plt) \n  )\n\n\n\nConfirm the new coding of race_clean.\n\n\n\nShow the code solution\ndf_clean |&gt; \n  count(race_clean, race)\n\n\n# A tibble: 9 √ó 3\n  race_clean       race                 n\n  &lt;fct&gt;            &lt;chr&gt;            &lt;int&gt;\n1 Caucasian        Caucasian           17\n2 African-American African-American     4\n3 African-American afromerican          2\n4 Other            H/API                1\n5 Other            Mixed                1\n6 Other            Other                2\n7 AmerInd          AmerInd              1\n8 Asian            Asian                1\n9 Hawaiian         Hawaiian             1\n\n\nShow the code solution\ndf_clean |&gt; \n  count(race_clean)\n\n\n# A tibble: 6 √ó 2\n  race_clean           n\n  &lt;fct&gt;            &lt;int&gt;\n1 Caucasian           17\n2 African-American     6\n3 Other                4\n4 AmerInd              1\n5 Asian                1\n6 Hawaiian             1"
  },
  {
    "objectID": "exercises.html#ph1",
    "href": "exercises.html#ph1",
    "title": "Data Cleaning: Exercises",
    "section": "PH1",
    "text": "PH1"
  },
  {
    "objectID": "exercises.html#ph2",
    "href": "exercises.html#ph2",
    "title": "Data Cleaning: Exercises",
    "section": "PH2",
    "text": "PH2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Principles of Data Cleaning",
    "section": "",
    "text": "üóì June 6, 2023 | 11:00am - 2:00pm EDT\nüè® Virtual\nüí• FREE workshop registration"
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Principles of Data Cleaning",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nTo import Excel files with (common, messy) data problems.\nTo address and clean common messy data problems in each variable\nTo address and clean data with more complex meta-problems, like pivoting to long format for data analysis, dealing with multi-column headers, color-coded data (gah!), and un-pivoting pivot tables into tidy data."
  },
  {
    "objectID": "index.html#is-this-course-for-me",
    "href": "index.html#is-this-course-for-me",
    "title": "Principles of Data Cleaning",
    "section": "Is this course for me?",
    "text": "Is this course for me?\nIf your answer to any of the following questions is ‚Äúyes‚Äù, then this is the right workshop for you.\n\nDo you frequently receive untidy data for analysis in Excel spreadsheets?\nDoes this drive you slightly batty?\nDo you want to learn how to make your life easier with a suite of data cleaning tools?\n\nThe workshop is designed for those with some experience in R. It will be assumed that participants can perform basic data manipulation. Experience with the {tidyverse} and the %&gt;%/|&gt; operator is a plus, but not required."
  },
  {
    "objectID": "index.html#prework",
    "href": "index.html#prework",
    "title": "Principles of Data Cleaning",
    "section": "Prework",
    "text": "Prework\nThis workshop will largely be conducted in the Posit Cloud environment. Please create a login to the Posit Cloud instance of this workshop here:\nPosit Cloud Medical Cleaning Workshop.\nIf you will not be using the Posit Cloud instance, you can just watch along as the instructors teach.\nIf you would like to try this out on your own computer, please have the following installed and configured on your machine.\n\nRecent version of R\nRecent version of RStudio\nRecent version of packages used in workshop.\ninstll_pkgs &lt;- c(\"tidyverse\", \"tidyxl\", \"unpivotr\", \"readxl\", \"openxlsx\", \"janitor\", \"gtsummary\", \"here\", \"padr\")\ninstall.packages(instll_pkgs)\nEnsure you can knit R markdown documents\nOpen RStudio and create a new Rmarkdown document\nSave the document and check you are able to knit it.\nEnsure you can import data from a Microsoft Excel spreadsheet to R\n\nSave a a Microsoft Excel spreadsheet in a known folder on your computer.\nOpen RStudio install/load (library) the packages {readxl} (link) and {openxlsx} (link)\nImport the data from the spreadsheet into R using the path to the correct folder with either package."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons 4.0 International."
  },
  {
    "objectID": "slides/index.html#licensing",
    "href": "slides/index.html#licensing",
    "title": "Data Cleaning",
    "section": "Licensing",
    "text": "Licensing\n\nThis work is licensed under Creative Commons Zero v1.0 Universal."
  },
  {
    "objectID": "slides/index.html#instructors",
    "href": "slides/index.html#instructors",
    "title": "Data Cleaning",
    "section": "Instructors",
    "text": "Instructors\n\n\nCrystal Lewis\n\n\nShannon Pileggi\n\n\nPeter Higgins"
  },
  {
    "objectID": "slides/index.html#scope",
    "href": "slides/index.html#scope",
    "title": "Data Cleaning",
    "section": "Scope",
    "text": "Scope\n\nTaming the Data Beast, by Allison HorstTaming the Data Beast, from Allison Horst‚Äôs Data Science Illustrations"
  },
  {
    "objectID": "slides/index.html#schedule",
    "href": "slides/index.html#schedule",
    "title": "Data Cleaning",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\nTime\nActivity\n\n\n\n\n11:00 - 11:50\nCrystal Lewis (Data management best practices)\n\n\n11:50 - 12:00\nBreak\n\n\n12:00 - 12:50\nShannon Pileggi (Data cleaning fundamentals)\n\n\n12:50 - 12:00\nBreak\n\n\n01:00 - 02:00\nPeter Higgins (Data wrangling & reshaping)\n\n\n\n\nPlease add any questions to the public Zoom chat. These may be answered in the moment or addressed at the end depending on context."
  },
  {
    "objectID": "slides/index.html#pipes",
    "href": "slides/index.html#pipes",
    "title": "Data Cleaning",
    "section": "Pipes",
    "text": "Pipes\n\n2014+ magrittr pipe %&gt;%\n2021+ (R \\(\\geq\\) 4.1.0) native R pipe |&gt;\n\n2022 Isabella Vel√°squez Understanding the native R pipe |&gt; https://ivelasq.rbind.io/blog/understanding-the-r-pipe/\n\n\n\n\n\nwhatever(arg1, arg2, arg3, ...)\n\narg1 |&gt;  \n  whatever(arg2, arg3)\n\n\n\n\n\nmean(0:10)\n\n0:10 |&gt; \n  mean()\n\n\n\n\nChange CTRL + Shift + M shortcut to native pipe:\nTools -&gt; Global Options -&gt; Code -&gt;\n¬†¬† Editing -&gt; check Use Native Pipe Operator"
  },
  {
    "objectID": "slides/index.html#r-for-data-science-ch-18-pipes",
    "href": "slides/index.html#r-for-data-science-ch-18-pipes",
    "title": "Data Cleaning",
    "section": "R for Data Science: Ch 18 Pipes",
    "text": "R for Data Science: Ch 18 Pipes\n\n\nhttps://r4ds.had.co.nz/pipes.html#pipes"
  },
  {
    "objectID": "slides/index.html#namespacing",
    "href": "slides/index.html#namespacing",
    "title": "Data Cleaning",
    "section": "Namespacing",
    "text": "Namespacing\ndplyr::select()\n\ntells R explicitly to use the function select from the package dplyr\ncan help to avoid name conflicts (e.g., MASS::select())\ndoes not require library(dplyr)\n\n\n\n\n\nlibrary(dplyr)\n\nselect(mtcars, mpg, cyl) \n\nmtcars |&gt;  \n  select(mpg, cyl) \n\n\n\n\n\n# library(dplyr) not needed\n\ndplyr::select(mtcars, mpg, cyl) \n\nmtcars |&gt;  \n  dplyr::select(mpg, cyl)"
  },
  {
    "objectID": "slides/index.html#slide-1",
    "href": "slides/index.html#slide-1",
    "title": "Data Cleaning",
    "section": "Slide 1",
    "text": "Slide 1"
  },
  {
    "objectID": "slides/index.html#slide-2",
    "href": "slides/index.html#slide-2",
    "title": "Data Cleaning",
    "section": "Slide 2",
    "text": "Slide 2"
  },
  {
    "objectID": "slides/index.html#slide-1-1",
    "href": "slides/index.html#slide-1-1",
    "title": "Data Cleaning",
    "section": "Slide 1",
    "text": "Slide 1"
  },
  {
    "objectID": "slides/index.html#slide-2-1",
    "href": "slides/index.html#slide-2-1",
    "title": "Data Cleaning",
    "section": "Slide 2",
    "text": "Slide 2"
  },
  {
    "objectID": "slides/index.html#variable-names",
    "href": "slides/index.html#variable-names",
    "title": "Data Cleaning",
    "section": "Variable names",
    "text": "Variable names\nOriginal variable names in excel:\n\n\n\nVariable names import as shown, with modifications from readxl::read_excel() to ensure uniqueness:"
  },
  {
    "objectID": "slides/index.html#variable-names-cleaner",
    "href": "slides/index.html#variable-names-cleaner",
    "title": "Data Cleaning",
    "section": "Variable names, cleaner",
    "text": "Variable names, cleaner\nVariable names as imported:\n\n\n\njanitor::clean_names() removes special characters and implements snake case by default:\n\ndf_clean &lt;- df_raw |&gt; \n  janitor::clean_names()"
  },
  {
    "objectID": "slides/index.html#remove-empty-columns-or-rows",
    "href": "slides/index.html#remove-empty-columns-or-rows",
    "title": "Data Cleaning",
    "section": "Remove empty columns or rows",
    "text": "Remove empty columns or rows\n\nProblemSolutionConfirm\n\n\n\ndf_clean |&gt; \n  select(pat_id, race:start_bp) |&gt; \n  slice(13:18)\n\n# A tibble: 6 √ó 5\n  pat_id race             dob                 x7    start_bp\n  &lt;chr&gt;  &lt;chr&gt;            &lt;dttm&gt;              &lt;lgl&gt; &lt;chr&gt;   \n1 013    Caucasian        1948-02-27 00:00:00 NA    118/73  \n2 014    African-American 1966-04-22 00:00:00 NA    106/59  \n3 015    H/API            1978-08-11 00:00:00 NA    112/69  \n4 &lt;NA&gt;   &lt;NA&gt;             NA                  NA    &lt;NA&gt;    \n5 016    African-American 1998-10-28 00:00:00 NA    114/76  \n6 017    Caucasian        2001-01-09 00:00:00 NA    124/80  \n\n\n\n\n\ndf_clean &lt;- df_raw |&gt; \n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\"))\n\n\n\ndf_clean |&gt; \n  select(pat_id, race:start_bp) |&gt; \n  slice(13:18)\n\n# A tibble: 6 √ó 4\n  pat_id race             dob                 start_bp\n  &lt;chr&gt;  &lt;chr&gt;            &lt;dttm&gt;              &lt;chr&gt;   \n1 013    Caucasian        1948-02-27 00:00:00 118/73  \n2 014    African-American 1966-04-22 00:00:00 106/59  \n3 015    H/API            1978-08-11 00:00:00 112/69  \n4 016    African-American 1998-10-28 00:00:00 114/76  \n5 017    Caucasian        2001-01-09 00:00:00 124/80  \n6 018    Caucasian        1994-03-07 00:00:00 120/68  \n\n\n\n\n\n\n\n#\ndf_raw |&gt;\n  janitor::clean_names() |&gt; \n  glimpse()\n\nRows: 31\nColumns: 38\n$ pat_id                           &lt;chr&gt; \"001\", \"002\", \"003\", \"004\", \"005\", \"0‚Ä¶\n$ treatment                        &lt;chr&gt; \"upa\", \"uste\", \"oza\", \"upa\", \"oza\", \"‚Ä¶\n$ start_date                       &lt;dbl&gt; 44208, 44215, 44230, 44245, 44255, 44‚Ä¶\n$ ethnic                           &lt;chr&gt; \"hispanic\", \"not hispanic\", \"not hisp‚Ä¶\n$ race                             &lt;chr&gt; \"Caucasian\", \"Caucasian\", \"African-Am‚Ä¶\n$ dob                              &lt;dttm&gt; 2005-01-07, 1937-04-13, 1946-06-06, ‚Ä¶\n$ x7                               &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ start_bp                         &lt;chr&gt; \"114/72\", \"132/86\", \"124/92\", \"144/83‚Ä¶\n$ pre_post_wt_kg                   &lt;chr&gt; \"84/82\", \"77/77\", \"74/75\", \"66/65\", \"‚Ä¶\n$ start_mes                        &lt;dbl&gt; 3, 2, 1, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3‚Ä¶\n$ start_bss                        &lt;dbl&gt; 75.45589, 53.62239, 25.52527, 79.3659‚Ä¶\n$ start_abd_score                  &lt;dbl&gt; 80.59025, 53.64479, 26.15548, 77.9491‚Ä¶\n$ start_sys                        &lt;dbl&gt; 81.45415, 52.60911, 27.55523, 79.8218‚Ä¶\n$ start_coping                     &lt;dbl&gt; 50.41090, 29.56833, 15.20377, 51.2653‚Ä¶\n$ start_emo                        &lt;dbl&gt; 73.32378, 55.72461, 36.56135, 80.7601‚Ä¶\n$ daily_life_impact_score_at_start &lt;dbl&gt; 86.88945, 56.10371, 31.38942, 84.8523‚Ä¶\n$ start_wbc                        &lt;dbl&gt; 8.2, 10.1, 5.5, 4.7, 8.9, 9.3, 5.6, 9‚Ä¶\n$ start_plt                        &lt;chr&gt; \"273K/microL\", \"414K/microL\", \"323K/m‚Ä¶\n$ start_na                         &lt;chr&gt; \"137mmol/L\", \"142mmol/L\", \"140mmol/L\"‚Ä¶\n$ start_k                          &lt;chr&gt; \"3.7\", \"4.0999999999999996\", \"4.3\", \"‚Ä¶\n$ end_month                        &lt;dbl&gt; 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9‚Ä¶\n$ end_day                          &lt;dbl&gt; 14, 21, 6, 22, 30, 4, 10, 15, 22, 26,‚Ä¶\n$ end_year                         &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2‚Ä¶\n$ end_mes                          &lt;dbl&gt; 0, 1, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 1‚Ä¶\n$ end_bss                          &lt;dbl&gt; 9.455894, 31.622388, 25.525267, 35.36‚Ä¶\n$ end_abd                          &lt;dbl&gt; 20.590252, 33.644791, 26.155480, 37.9‚Ä¶\n$ end_sys                          &lt;dbl&gt; 9.454153, 28.609114, 27.555232, 31.82‚Ä¶\n$ end_coping                       &lt;dbl&gt; 23.41090, 20.56833, 15.20377, 33.2653‚Ä¶\n$ end_emo                          &lt;chr&gt; \"31.980531232702354\", \"43.15496159247‚Ä¶\n$ end_dl                           &lt;chr&gt; \"6.6605585857717573\", \"30.53917899804‚Ä¶\n$ end_wbc                          &lt;dbl&gt; 8.562208, 11.135466, 3.000000, 5.6919‚Ä¶\n$ end_plt                          &lt;dbl&gt; 201, 340, 256, 327, 432, 348, 181, 12‚Ä¶\n$ end_na                           &lt;dbl&gt; 137.3278, 142.2140, 140.0831, 139.158‚Ä¶\n$ end_k                            &lt;dbl&gt; 3.741212, 4.148464, 4.471147, 3.64134‚Ä¶\n$ fake_street                      &lt;chr&gt; \"990¬†Mohammad¬†Mountain\", \"8512¬†O'Conn‚Ä¶\n$ fake_city                        &lt;chr&gt; \"North¬†Sigmundville\", \"Port¬†Halstad\",‚Ä¶\n$ fake_state                       &lt;chr&gt; \"New¬†Mexico\", \"Missouri\", \"South¬†Caro‚Ä¶\n$ fake_zip                         &lt;dbl&gt; 96074, 11264, 57246, 31457, 30711, 52‚Ä¶\n\n\n\n\ndf_raw |&gt; \n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 37\n$ pat_id                           &lt;chr&gt; \"001\", \"002\", \"003\", \"004\", \"005\", \"0‚Ä¶\n$ treatment                        &lt;chr&gt; \"upa\", \"uste\", \"oza\", \"upa\", \"oza\", \"‚Ä¶\n$ start_date                       &lt;dbl&gt; 44208, 44215, 44230, 44245, 44255, 44‚Ä¶\n$ ethnic                           &lt;chr&gt; \"hispanic\", \"not hispanic\", \"not hisp‚Ä¶\n$ race                             &lt;chr&gt; \"Caucasian\", \"Caucasian\", \"African-Am‚Ä¶\n$ dob                              &lt;dttm&gt; 2005-01-07, 1937-04-13, 1946-06-06, ‚Ä¶\n$ start_bp                         &lt;chr&gt; \"114/72\", \"132/86\", \"124/92\", \"144/83‚Ä¶\n$ pre_post_wt_kg                   &lt;chr&gt; \"84/82\", \"77/77\", \"74/75\", \"66/65\", \"‚Ä¶\n$ start_mes                        &lt;dbl&gt; 3, 2, 1, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3‚Ä¶\n$ start_bss                        &lt;dbl&gt; 75.45589, 53.62239, 25.52527, 79.3659‚Ä¶\n$ start_abd_score                  &lt;dbl&gt; 80.59025, 53.64479, 26.15548, 77.9491‚Ä¶\n$ start_sys                        &lt;dbl&gt; 81.45415, 52.60911, 27.55523, 79.8218‚Ä¶\n$ start_coping                     &lt;dbl&gt; 50.41090, 29.56833, 15.20377, 51.2653‚Ä¶\n$ start_emo                        &lt;dbl&gt; 73.32378, 55.72461, 36.56135, 80.7601‚Ä¶\n$ daily_life_impact_score_at_start &lt;dbl&gt; 86.88945, 56.10371, 31.38942, 84.8523‚Ä¶\n$ start_wbc                        &lt;dbl&gt; 8.2, 10.1, 5.5, 4.7, 8.9, 9.3, 5.6, 9‚Ä¶\n$ start_plt                        &lt;chr&gt; \"273K/microL\", \"414K/microL\", \"323K/m‚Ä¶\n$ start_na                         &lt;chr&gt; \"137mmol/L\", \"142mmol/L\", \"140mmol/L\"‚Ä¶\n$ start_k                          &lt;chr&gt; \"3.7\", \"4.0999999999999996\", \"4.3\", \"‚Ä¶\n$ end_month                        &lt;dbl&gt; 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9‚Ä¶\n$ end_day                          &lt;dbl&gt; 14, 21, 6, 22, 30, 4, 10, 15, 22, 26,‚Ä¶\n$ end_year                         &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2‚Ä¶\n$ end_mes                          &lt;dbl&gt; 0, 1, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 1‚Ä¶\n$ end_bss                          &lt;dbl&gt; 9.455894, 31.622388, 25.525267, 35.36‚Ä¶\n$ end_abd                          &lt;dbl&gt; 20.590252, 33.644791, 26.155480, 37.9‚Ä¶\n$ end_sys                          &lt;dbl&gt; 9.454153, 28.609114, 27.555232, 31.82‚Ä¶\n$ end_coping                       &lt;dbl&gt; 23.41090, 20.56833, 15.20377, 33.2653‚Ä¶\n$ end_emo                          &lt;chr&gt; \"31.980531232702354\", \"43.15496159247‚Ä¶\n$ end_dl                           &lt;chr&gt; \"6.6605585857717573\", \"30.53917899804‚Ä¶\n$ end_wbc                          &lt;dbl&gt; 8.562208, 11.135466, 3.000000, 5.6919‚Ä¶\n$ end_plt                          &lt;dbl&gt; 201, 340, 256, 327, 432, 348, 181, 12‚Ä¶\n$ end_na                           &lt;dbl&gt; 137.3278, 142.2140, 140.0831, 139.158‚Ä¶\n$ end_k                            &lt;dbl&gt; 3.741212, 4.148464, 4.471147, 3.64134‚Ä¶\n$ fake_street                      &lt;chr&gt; \"990¬†Mohammad¬†Mountain\", \"8512¬†O'Conn‚Ä¶\n$ fake_city                        &lt;chr&gt; \"North¬†Sigmundville\", \"Port¬†Halstad\",‚Ä¶\n$ fake_state                       &lt;chr&gt; \"New¬†Mexico\", \"Missouri\", \"South¬†Caro‚Ä¶\n$ fake_zip                         &lt;dbl&gt; 96074, 11264, 57246, 31457, 30711, 52‚Ä¶"
  },
  {
    "objectID": "slides/index.html#recoding",
    "href": "slides/index.html#recoding",
    "title": "Data Cleaning",
    "section": "Recoding",
    "text": "Recoding\n\nProblemSolutionConfirm\n\n\n\ndf_clean |&gt; \n  count(ethnic)\n\n# A tibble: 5 √ó 2\n  ethnic           n\n  &lt;chr&gt;        &lt;int&gt;\n1 Hispanic         1\n2 NOT hispanic     1\n3 hispamnic        1\n4 hispanic         3\n5 not hispanic    24\n\n\n\n\n\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    )\n  )\n\ndf_clean |&gt; \n  count(ethnic_clean)\n\n# A tibble: 2 √ó 2\n  ethnic_clean     n\n  &lt;chr&gt;        &lt;int&gt;\n1 hispanic         5\n2 not hispanic    25\n\n\n\n\n\ndf_clean |&gt; \n  count(ethnic_clean, ethnic)\n\n# A tibble: 5 √ó 3\n  ethnic_clean ethnic           n\n  &lt;chr&gt;        &lt;chr&gt;        &lt;int&gt;\n1 hispanic     Hispanic         1\n2 hispanic     hispamnic        1\n3 hispanic     hispanic         3\n4 not hispanic NOT hispanic     1\n5 not hispanic not hispanic    24"
  },
  {
    "objectID": "slides/index.html#exercise",
    "href": "slides/index.html#exercise",
    "title": "Data Cleaning",
    "section": "Exercise",
    "text": "Exercise\n\nComplete Data Cleaning Fundamentals Exercise SP1.\n\n‚Äì&gt; Take me to the exercises &lt;‚Äì\n\n\n\n‚àí+\n05:00"
  },
  {
    "objectID": "slides/index.html#replace-values-with-missing",
    "href": "slides/index.html#replace-values-with-missing",
    "title": "Data Cleaning",
    "section": "Replace values with missing",
    "text": "Replace values with missing\n\nProblemSolutionConfirm\n\n\n\n\n\ndf_clean |&gt; \n  count(end_na) \n\n# A tibble: 30 √ó 2\n   end_na     n\n    &lt;dbl&gt; &lt;int&gt;\n 1   -99      1\n 2   133.     1\n 3   135.     1\n 4   135.     1\n 5   136.     1\n 6   137.     1\n 7   137.     1\n 8   138.     1\n 9   138.     1\n10   138.     1\n# ‚Ñπ 20 more rows\n\n\n\n\ndf_clean |&gt; \n  ggplot(aes(x = end_na)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99)\n  ) \n\n\n\n\n\n\ndf_clean |&gt; \n  count(end_na, end_na_clean) \n\n# A tibble: 30 √ó 3\n   end_na end_na_clean     n\n    &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n 1   -99           NA      1\n 2   133.         133.     1\n 3   135.         135.     1\n 4   135.         135.     1\n 5   136.         136.     1\n 6   137.         137.     1\n 7   137.         137.     1\n 8   138.         138.     1\n 9   138.         138.     1\n10   138.         138.     1\n# ‚Ñπ 20 more rows\n\n\n\n\ndf_clean |&gt; \n  ggplot(aes(x = end_na_clean)) +\n  geom_histogram()"
  },
  {
    "objectID": "slides/index.html#incorrect-variable-type",
    "href": "slides/index.html#incorrect-variable-type",
    "title": "Data Cleaning",
    "section": "Incorrect variable type",
    "text": "Incorrect variable type\n\nProblemSolutionConfirm\n\n\n\n\n\ndf_raw |&gt; \n  select(end_emo) |&gt; \n  glimpse()\n\nRows: 31\nColumns: 1\n$ end_emo &lt;chr&gt; \"31.980531232702354\", \"43.154961592472482\", \"36.88112394645107‚Ä¶\n\n\n\n\n\nmean(df_raw[[\"end_emo\"]], na.rm = TRUE)\n\nWarning in mean.default(df_raw[[\"end_emo\"]], na.rm = TRUE): argument is not\nnumeric or logical: returning NA\n\n\n[1] NA\n\n\n\n\n\ndf_raw[[\"end_emo\"]]\n\n [1] \"31.980531232702354\" \"43.154961592472482\" \"36.881123946451076\"\n [4] \"58.670309483569042\" \"58.863864661125419\" \"34.593046073414015\"\n [7] \"63.285059520403976\" \"65.313599031979081\" \"27.976656095216335\"\n[10] \"46.802992507671597\" \"33.122563864954309\" \"49.240520034972612\"\n[13] \"47.050604139781761\" \"54.487640962873577\" \"not done\"          \n[16] NA                   \"49.084529664712441\" \"27.370965295845295\"\n[19] \"60.432712720552317\" \"26.162987564588903\" \"48.329539382030802\"\n[22] \"40.735196376550661\" \"27.000188739872502\" \"57.019771433515629\"\n[25] \"39.783229029414606\" \"52.110256961065794\" \"37.098188331548307\"\n[28] \"39.264033750725694\" \"70.34798440037369\"  \"29.839211956263874\"\n[31] \"42.853436653960713\"\n\n\n\n\n\n\n\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |&gt; as.numeric()\n  ) \n\n\n\n\n\n\ndf_clean |&gt; \n  select(end_emo_clean) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 1\n$ end_emo_clean &lt;dbl&gt; 31.98053, 43.15496, 36.88112, 58.67031, 58.86386, 34.593‚Ä¶\n\n\n\n\n\nmean(df_clean[[\"end_emo_clean\"]], na.rm = TRUE)\n\n[1] 44.78813\n\n\n\n\n\ndf_clean |&gt; \n  count(end_emo_clean, end_emo)\n\n# A tibble: 30 √ó 3\n   end_emo_clean end_emo                n\n           &lt;dbl&gt; &lt;chr&gt;              &lt;int&gt;\n 1          26.2 26.162987564588903     1\n 2          27.0 27.000188739872502     1\n 3          27.4 27.370965295845295     1\n 4          28.0 27.976656095216335     1\n 5          29.8 29.839211956263874     1\n 6          32.0 31.980531232702354     1\n 7          33.1 33.122563864954309     1\n 8          34.6 34.593046073414015     1\n 9          36.9 36.881123946451076     1\n10          37.1 37.098188331548307     1\n# ‚Ñπ 20 more rows"
  },
  {
    "objectID": "slides/index.html#correcting-dates",
    "href": "slides/index.html#correcting-dates",
    "title": "Data Cleaning",
    "section": "Correcting dates",
    "text": "Correcting dates\n\nProblemSolutionConfirm\n\n\n\ndf_raw |&gt; \n  select(start_date) |&gt; \n  glimpse()\n\nRows: 31\nColumns: 1\n$ start_date &lt;dbl&gt; 44208, 44215, 44230, 44245, 44255, 44259, 44264, 44999, 442‚Ä¶\n\n\n\n\n\ndf_raw[[\"start_date\"]]\n\n [1] 44208 44215 44230 44245 44255 44259 44264 44999 44276 44278 44297 44308\n[13] 44313 44318 44324    NA 44329 44332 44346 44358 44370 44383 44391 44397\n[25] 44412 44425 44434 44444 44461 44475 44500\n\n\n\n\n\n\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |&gt; as.numeric(),\n    start_date_clean = janitor::convert_to_date(start_date)\n  ) \n\n\n\n\n\n\ndf_clean |&gt; \n  select(start_date, start_date_clean) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 2\n$ start_date       &lt;dbl&gt; 44208, 44215, 44230, 44245, 44255, 44259, 44264, 4499‚Ä¶\n$ start_date_clean &lt;date&gt; 2021-01-12, 2021-01-19, 2021-02-03, 2021-02-18, 2021‚Ä¶\n\n\n\n\ndf_clean |&gt; \n  count(start_date, start_date_clean) \n\n# A tibble: 30 √ó 3\n   start_date start_date_clean     n\n        &lt;dbl&gt; &lt;date&gt;           &lt;int&gt;\n 1      44208 2021-01-12           1\n 2      44215 2021-01-19           1\n 3      44230 2021-02-03           1\n 4      44245 2021-02-18           1\n 5      44255 2021-02-28           1\n 6      44259 2021-03-04           1\n 7      44264 2021-03-09           1\n 8      44276 2021-03-21           1\n 9      44278 2021-03-23           1\n10      44297 2021-04-11           1\n# ‚Ñπ 20 more rows"
  },
  {
    "objectID": "slides/index.html#extracting-numbers-from-text",
    "href": "slides/index.html#extracting-numbers-from-text",
    "title": "Data Cleaning",
    "section": "Extracting numbers from text",
    "text": "Extracting numbers from text\n\nProblemSolutionConfirm\n\n\n\n\n\ndf_raw |&gt; \n  select(start_na) |&gt; \n  glimpse()\n\nRows: 31\nColumns: 1\n$ start_na &lt;chr&gt; \"137mmol/L\", \"142mmol/L\", \"140mmol/L\", \"139mmol/L\", \"144mmol/‚Ä¶\n\n\n\n\n\nmean(df_raw[[\"start_na\"]], na.rm = TRUE)\n\nWarning in mean.default(df_raw[[\"start_na\"]], na.rm = TRUE): argument is not\nnumeric or logical: returning NA\n\n\n[1] NA\n\n\n\n\n\ndf_raw[[\"start_na\"]]\n\n [1] \"137mmol/L\" \"142mmol/L\" \"140mmol/L\" \"139mmol/L\" \"144mmol/L\" \"145mmol/L\"\n [7] \"142mmol/L\" \"138mmol/L\" \"140mmol/L\" \"137mmol/L\" \"143mmol/L\" \"136mmol/L\"\n[13] \"135mmol/L\" \"141mmol/L\" \"133mmol/L\" NA          \"135mmol/L\" \"143mmol/L\"\n[19] \"136mmol/L\" \"144mmol/L\" \"145mmol/L\" \"140mmol/L\" \"141mmol/L\" \"142mmol/L\"\n[25] \"138mmol/L\" \"139mmol/L\" \"142mmol/L\" \"144mmol/L\" \"139mmol/L\" \"138mmol/L\"\n[31] \"140mmol/L\"\n\n\n\n\n\n\n\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |&gt; as.numeric(),\n    start_na_clean = parse_number(start_na)\n  ) \n\n\n\n\n\n\ndf_clean |&gt; \n  select(start_na_clean) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 1\n$ start_na_clean &lt;dbl&gt; 137, 142, 140, 139, 144, 145, 142, 138, 140, 137, 143, ‚Ä¶\n\n\n\n\n\nmean(df_clean[[\"start_na_clean\"]], na.rm = TRUE)\n\n[1] 139.9333\n\n\n\n\n\ndf_clean |&gt; \n  count(start_na_clean, start_na)\n\n# A tibble: 12 √ó 3\n   start_na_clean start_na      n\n            &lt;dbl&gt; &lt;chr&gt;     &lt;int&gt;\n 1            133 133mmol/L     1\n 2            135 135mmol/L     2\n 3            136 136mmol/L     2\n 4            137 137mmol/L     2\n 5            138 138mmol/L     3\n 6            139 139mmol/L     3\n 7            140 140mmol/L     4\n 8            141 141mmol/L     2\n 9            142 142mmol/L     4\n10            143 143mmol/L     2\n11            144 144mmol/L     3\n12            145 145mmol/L     2"
  },
  {
    "objectID": "slides/index.html#exercise-1",
    "href": "slides/index.html#exercise-1",
    "title": "Data Cleaning",
    "section": "Exercise",
    "text": "Exercise\n\nComplete Data Cleaning Fundamentals Exercise SP2.\n\n‚Äì&gt; Take me to the exercises &lt;‚Äì\n\n\n\n‚àí+\n05:00"
  },
  {
    "objectID": "slides/index.html#character-variable-should-be-a-factor",
    "href": "slides/index.html#character-variable-should-be-a-factor",
    "title": "Data Cleaning",
    "section": "Character variable should be a factor",
    "text": "Character variable should be a factor\n\nProblemSolutionConfirm\n\n\n\n\n\ndf_clean |&gt; \n  count(treatment)\n\n# A tibble: 3 √ó 2\n  treatment     n\n  &lt;chr&gt;     &lt;int&gt;\n1 oza          10\n2 upa          10\n3 uste         10\n\n\n\n\n\ndf_clean |&gt; \n  count(ethnic_clean)\n\n# A tibble: 2 √ó 2\n  ethnic_clean     n\n  &lt;chr&gt;        &lt;int&gt;\n1 hispanic         5\n2 not hispanic    25\n\n\n\n\n\ndf_clean |&gt; \n  select(treatment, ethnic_clean) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 2\n$ treatment    &lt;chr&gt; \"upa\", \"uste\", \"oza\", \"upa\", \"oza\", \"uste\", \"uste\", \"oza\"‚Ä¶\n$ ethnic_clean &lt;chr&gt; \"hispanic\", \"not hispanic\", \"not hispanic\", \"not hispanic‚Ä¶\n\n\n\n\ndf_clean |&gt; \n  select(treatment, ethnic_clean) |&gt; \n  tbl_summary(by = treatment)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      oza, N = 101\n      upa, N = 101\n      uste, N = 101\n    \n  \n  \n    ethnic_clean\n\n\n\n    ¬†¬†¬†¬†hispanic\n4 (40%)\n1 (10%)\n0 (0%)\n    ¬†¬†¬†¬†not hispanic\n6 (60%)\n9 (90%)\n10 (100%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\n\n\n\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ) |&gt; fct_infreq(),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |&gt; as.numeric(),\n    start_na_clean = parse_number(start_na),\n    treatment = fct_relevel(treatment, \"upa\", \"uste\", \"oza\")\n  ) \n\n\nSee the forcats package for other factor handling solutions.\n\n\n\n\n\ndf_clean |&gt; \n  count(treatment)\n\n# A tibble: 3 √ó 2\n  treatment     n\n  &lt;fct&gt;     &lt;int&gt;\n1 upa          10\n2 uste         10\n3 oza          10\n\n\n\n\n\ndf_clean |&gt; \n  count(ethnic_clean)\n\n# A tibble: 2 √ó 2\n  ethnic_clean     n\n  &lt;fct&gt;        &lt;int&gt;\n1 not hispanic    25\n2 hispanic         5\n\n\n\n\n\ndf_clean |&gt; \n  select(treatment, ethnic_clean) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 2\n$ treatment    &lt;fct&gt; upa, uste, oza, upa, oza, uste, uste, oza, upa, oza, upa,‚Ä¶\n$ ethnic_clean &lt;fct&gt; hispanic, not hispanic, not hispanic, not hispanic, not h‚Ä¶\n\n\n\n\ndf_clean |&gt; \n  select(treatment, ethnic_clean) |&gt; \n  tbl_summary(by = treatment)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      upa, N = 101\n      uste, N = 101\n      oza, N = 101\n    \n  \n  \n    ethnic_clean\n\n\n\n    ¬†¬†¬†¬†not hispanic\n9 (90%)\n10 (100%)\n6 (60%)\n    ¬†¬†¬†¬†hispanic\n1 (10%)\n0 (0%)\n4 (40%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "slides/index.html#exercise-2",
    "href": "slides/index.html#exercise-2",
    "title": "Data Cleaning",
    "section": "Exercise",
    "text": "Exercise\n\nComplete Data Cleaning Fundamentals Exercise SP3.\n\n‚Äì&gt; Take me to the exercises &lt;‚Äì\n\n\n\n‚àí+\n05:00"
  },
  {
    "objectID": "slides/index.html#separating-values",
    "href": "slides/index.html#separating-values",
    "title": "Data Cleaning",
    "section": "Separating values",
    "text": "Separating values\n\nProblemSolutionConfirm\n\n\n\ndf_clean |&gt; \n  select(start_bp) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 1\n$ start_bp &lt;chr&gt; \"114/72\", \"132/86\", \"124/92\", \"144/83\", \"122/78\", \"121/80\", \"‚Ä¶\n\n\n\n\n\nmean(df_clean[[\"start_bp\"]], na.rm = TRUE)\n\n[1] NA\n\n\n\n\n\n\ndf_clean[[\"start_bp\"]]\n\n [1] \"114/72\" \"132/86\" \"124/92\" \"144/83\" \"122/78\" \"121/80\" \"133/74\" \"116/73\"\n [9] \"118/66\" \"122/78\" \"126/82\" \"114/68\" \"118/73\" \"106/59\" \"112/69\" \"114/76\"\n[17] \"124/80\" \"120/68\" \"119/77\" \"116/74\" \"121/80\" \"112/58\" \"117/67\" \"118/73\"\n[25] \"116/74\" \"126/84\" \"144/96\" \"120/84\" \"115/75\" \"142/92\"\n\n\n\n\n\n\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ) |&gt; fct_infreq(),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |&gt; as.numeric(),\n    start_na_clean = parse_number(start_na),\n    treatment = fct_relevel(treatment, \"upa\", \"uste\", \"oza\")\n    ) |&gt;  \n  separate_wider_delim(start_bp, delim =\"/\", names = c(\"bp_systolic\", \"bp_diastolic\"), cols_remove = FALSE) |&gt; \n  mutate(across(c(bp_systolic, bp_diastolic), as.numeric)) \n\n\n\n\n\n\ndf_clean |&gt; \n  select(start_bp, bp_systolic, bp_diastolic) |&gt; \n  glimpse()\n\nRows: 30\nColumns: 3\n$ start_bp     &lt;chr&gt; \"114/72\", \"132/86\", \"124/92\", \"144/83\", \"122/78\", \"121/80‚Ä¶\n$ bp_systolic  &lt;dbl&gt; 114, 132, 124, 144, 122, 121, 133, 116, 118, 122, 126, 11‚Ä¶\n$ bp_diastolic &lt;dbl&gt; 72, 86, 92, 83, 78, 80, 74, 73, 66, 78, 82, 68, 73, 59, 6‚Ä¶\n\n\n\n\n\nmean(df_clean[[\"bp_systolic\"]], na.rm = TRUE)\n\n[1] 121.5333\n\nmean(df_clean[[\"bp_diastolic\"]], na.rm = TRUE)\n\n[1] 76.36667\n\n\n\n\n\n\ndf_clean[[\"bp_systolic\"]]\n\n [1] 114 132 124 144 122 121 133 116 118 122 126 114 118 106 112 114 124 120 119\n[20] 116 121 112 117 118 116 126 144 120 115 142\n\ndf_clean[[\"bp_diastolic\"]]\n\n [1] 72 86 92 83 78 80 74 73 66 78 82 68 73 59 69 76 80 68 77 74 80 58 67 73 74\n[26] 84 96 84 75 92"
  },
  {
    "objectID": "slides/index.html#assigning-labels",
    "href": "slides/index.html#assigning-labels",
    "title": "Data Cleaning",
    "section": "Assigning labels",
    "text": "Assigning labels\n\nProblemSolution 1Solution 2Solution 3Confirm 1Confirm 2\n\n\nWhat does anything mean?\n\nview(df_clean)\n\n\n\n\n\n\n# first import codebook\ndf_codebook &lt;- read_excel(\n  path = here(\"data\", \"messy_uc.xlsx\"),\n  sheet = \"Codebook\"\n)\ndf_codebook\n\n# A tibble: 33 √ó 5\n   Variable       Details                                      Units Range ...5 \n   &lt;chr&gt;          &lt;chr&gt;                                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 pat_id         Patient Identifier                           digi‚Ä¶ 001-‚Ä¶ &lt;NA&gt; \n 2 treatment      Treatment for UC                             &lt;NA&gt;  upad‚Ä¶ &lt;NA&gt; \n 3 start_date     Date of start of treatment                   digi‚Ä¶ YYYY‚Ä¶ &lt;NA&gt; \n 4 ethnic         Ethnicity - hispanic or not hispanic         &lt;NA&gt;  hisp‚Ä¶ &lt;NA&gt; \n 5 race           Race - one of 7 choices                      &lt;NA&gt;  cauc‚Ä¶ &lt;NA&gt; \n 6 dob            date of birth                                digi‚Ä¶ YYYY‚Ä¶ &lt;NA&gt; \n 7 start_bp       blood pressure at start - systolic/diastolic mm Hg syst‚Ä¶ &lt;NA&gt; \n 8 pre/post_wt_kg weight in kilograms at start/end             kilo‚Ä¶ 48-1‚Ä¶ &lt;NA&gt; \n 9 start_mes      Mayo endoscopic Score at start of treatment  poin‚Ä¶ 0-3   &lt;NA&gt; \n10 start_bss      Bowel symptom score at start                 poin‚Ä¶ 0-100 QOL ‚Ä¶\n# ‚Ñπ 23 more rows\n\n\n\n\n\n# second create a named vector of variable names and variable labels\nvec_variables &lt;- df_codebook |&gt; \n  select(Variable, Details) |&gt; \n  deframe()\n\nvec_variables\n\n                                        pat_id \n                          \"Patient Identifier\" \n                                     treatment \n                            \"Treatment for UC\" \n                                    start_date \n                  \"Date of start of treatment\" \n                                        ethnic \n        \"Ethnicity - hispanic or not hispanic\" \n                                          race \n                     \"Race - one of 7 choices\" \n                                           dob \n                               \"date of birth\" \n                                      start_bp \n\"blood pressure at start - systolic/diastolic\" \n                                pre/post_wt_kg \n            \"weight in kilograms at start/end\" \n                                     start_mes \n \"Mayo endoscopic Score at start of treatment\" \n                                     start_bss \n                \"Bowel symptom score at start\" \n                                     start_abd \n            \"Abdominal symptom score at start\" \n                                     start_sys \n             \"Systemic symptom score at start\" \n                                  start_coping \n                       \"Coping score at start\" \n                                     start_emo \n            \"Emotional symptom score at start\" \n                                      start_dl \n       \"Impact on Daily living score at start\" \n                                     start_wbc \n    \"White blood cell count in blood at start\" \n                                     start_plt \n            \"Platelet count in blood at start\" \n                                      start_na \n              \"Sodium level in serum at start\" \n                                       start_k \n           \"Potassium level in serum at start\" \n                                     end_month \n                          \"Month of end visit\" \n                                       end_day \n                            \"Day of end visit\" \n                                      end_year \n                           \"Year of end visit\" \n                                       end_mes \n   \"Mayo endoscopic Score at end of treatment\" \n                                       end_bss \n                  \"Bowel symptom score at end\" \n                                       end_abd \n              \"Abdominal symptom score at end\" \n                                       end_sys \n               \"Systemic symptom score at end\" \n                                    end_coping \n                         \"Coping score at end\" \n                                       end_emo \n              \"Emotional symptom score at end\" \n                                        end_dl \n         \"Impact on Daily living score at end\" \n                                       end_wbc \n      \"White blood cell count in blood at end\" \n                                       end_plt \n              \"Platelet count in blood at end\" \n                                        end_na \n                \"Sodium level in serum at end\" \n                                         end_k \n             \"Potassium level in serum at end\" \n\n\n\n\n\n# assign labels to the data set\ndf_clean &lt;- df_raw |&gt;\n  janitor::clean_names() |&gt; \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |&gt; \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ) |&gt; fct_infreq(),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |&gt; as.numeric(),\n    start_na_clean = parse_number(start_na),\n    treatment = fct_relevel(treatment, \"upa\", \"uste\", \"oza\")\n    ) |&gt;  \n  separate_wider_delim(start_bp, delim =\"/\", names = c(\"bp_systolic\", \"bp_diastolic\"), cols_remove = FALSE) |&gt; \n  mutate(across(c(bp_systolic, bp_diastolic), as.numeric)) |&gt; \n  # assign labels to all variables from the codebook\n  labelled::set_variable_labels(!!!vec_variables, .strict = FALSE) |&gt; \n  # assign labels to new derived variables that did not exist in the code book\n  labelled::set_variable_labels(\n    ethnic_clean = \"Ethnicity\",\n    end_na_clean = \"Sodium level in serum at end\",\n    end_emo_clean = \"Emotional symptom score at end\",\n    bp_systolic = \"Systolic blood pressure\",\n    bp_diastolic = \"Diastolic blood pressure\"\n  )\n\n\n\n\n# view entire data set\ndf_clean |&gt; view()\n\n\n\n\n\n\n# view structure of data frame\ndf_clean |&gt; str()\n\ntibble [30 √ó 43] (S3: tbl_df/tbl/data.frame)\n $ pat_id                          : chr [1:30] \"001\" \"002\" \"003\" \"004\" ...\n  ..- attr(*, \"label\")= chr \"Patient Identifier\"\n $ treatment                       : Factor w/ 3 levels \"upa\",\"uste\",\"oza\": 1 2 3 1 3 2 2 3 1 3 ...\n  ..- attr(*, \"label\")= chr \"Treatment for UC\"\n $ start_date                      : num [1:30] 44208 44215 44230 44245 44255 ...\n  ..- attr(*, \"label\")= chr \"Date of start of treatment\"\n $ ethnic                          : chr [1:30] \"hispanic\" \"not hispanic\" \"not hispanic\" \"not hispanic\" ...\n  ..- attr(*, \"label\")= chr \"Ethnicity - hispanic or not hispanic\"\n $ race                            : chr [1:30] \"Caucasian\" \"Caucasian\" \"African-American\" \"Caucasian\" ...\n  ..- attr(*, \"label\")= chr \"Race - one of 7 choices\"\n $ dob                             : POSIXct[1:30], format: \"2005-01-07\" \"1937-04-13\" ...\n $ bp_systolic                     : num [1:30] 114 132 124 144 122 121 133 116 118 122 ...\n  ..- attr(*, \"label\")= chr \"Systolic blood pressure\"\n $ bp_diastolic                    : num [1:30] 72 86 92 83 78 80 74 73 66 78 ...\n  ..- attr(*, \"label\")= chr \"Diastolic blood pressure\"\n $ start_bp                        : chr [1:30] \"114/72\" \"132/86\" \"124/92\" \"144/83\" ...\n  ..- attr(*, \"label\")= chr \"blood pressure at start - systolic/diastolic\"\n $ pre_post_wt_kg                  : chr [1:30] \"84/82\" \"77/77\" \"74/75\" \"66/65\" ...\n $ start_mes                       : num [1:30] 3 2 1 3 3 2 3 3 2 3 ...\n  ..- attr(*, \"label\")= chr \"Mayo endoscopic Score at start of treatment\"\n $ start_bss                       : num [1:30] 75.5 53.6 25.5 79.4 79.5 ...\n  ..- attr(*, \"label\")= chr \"Bowel symptom score at start\"\n $ start_abd_score                 : num [1:30] 80.6 53.6 26.2 77.9 78.4 ...\n $ start_sys                       : num [1:30] 81.5 52.6 27.6 79.8 79.2 ...\n  ..- attr(*, \"label\")= chr \"Systemic symptom score at start\"\n $ start_coping                    : num [1:30] 50.4 29.6 15.2 51.3 43.1 ...\n  ..- attr(*, \"label\")= chr \"Coping score at start\"\n $ start_emo                       : num [1:30] 73.3 55.7 36.6 80.8 72.5 ...\n  ..- attr(*, \"label\")= chr \"Emotional symptom score at start\"\n $ daily_life_impact_score_at_start: num [1:30] 86.9 56.1 31.4 84.9 87.3 ...\n $ start_wbc                       : num [1:30] 8.2 10.1 5.5 4.7 8.9 9.3 5.6 9.7 8.3 7.6 ...\n  ..- attr(*, \"label\")= chr \"White blood cell count in blood at start\"\n $ start_plt                       : chr [1:30] \"273K/microL\" \"414K/microL\" \"323K/microL\" \"389K/microL\" ...\n  ..- attr(*, \"label\")= chr \"Platelet count in blood at start\"\n $ start_na                        : chr [1:30] \"137mmol/L\" \"142mmol/L\" \"140mmol/L\" \"139mmol/L\" ...\n  ..- attr(*, \"label\")= chr \"Sodium level in serum at start\"\n $ start_k                         : chr [1:30] \"3.7\" \"4.0999999999999996\" \"4.3\" \"3.5\" ...\n  ..- attr(*, \"label\")= chr \"Potassium level in serum at start\"\n $ end_month                       : num [1:30] 6 6 7 7 7 8 8 8 8 8 ...\n  ..- attr(*, \"label\")= chr \"Month of end visit\"\n $ end_day                         : num [1:30] 14 21 6 22 30 4 10 15 22 26 ...\n  ..- attr(*, \"label\")= chr \"Day of end visit\"\n $ end_year                        : num [1:30] 2021 2021 2021 2021 2021 ...\n  ..- attr(*, \"label\")= chr \"Year of end visit\"\n $ end_mes                         : num [1:30] 0 1 1 1 2 1 2 2 0 1 ...\n  ..- attr(*, \"label\")= chr \"Mayo endoscopic Score at end of treatment\"\n $ end_bss                         : num [1:30] 9.46 31.62 25.53 35.37 57.53 ...\n  ..- attr(*, \"label\")= chr \"Bowel symptom score at end\"\n $ end_abd                         : num [1:30] 20.6 33.6 26.2 37.9 58.4 ...\n  ..- attr(*, \"label\")= chr \"Abdominal symptom score at end\"\n $ end_sys                         : num [1:30] 9.45 28.61 27.56 31.82 55.19 ...\n  ..- attr(*, \"label\")= chr \"Systemic symptom score at end\"\n $ end_coping                      : num [1:30] 23.4 20.6 15.2 33.3 34.1 ...\n  ..- attr(*, \"label\")= chr \"Coping score at end\"\n $ end_emo                         : chr [1:30] \"31.980531232702354\" \"43.154961592472482\" \"36.881123946451076\" \"58.670309483569042\" ...\n  ..- attr(*, \"label\")= chr \"Emotional symptom score at end\"\n $ end_dl                          : chr [1:30] \"6.6605585857717573\" \"30.539178998046562\" \"32.798667784920319\" \"33.781373664703942\" ...\n  ..- attr(*, \"label\")= chr \"Impact on Daily living score at end\"\n $ end_wbc                         : num [1:30] 8.56 11.14 3 5.69 4.8 ...\n  ..- attr(*, \"label\")= chr \"White blood cell count in blood at end\"\n $ end_plt                         : num [1:30] 201 340 256 327 432 348 181 128 135 238 ...\n  ..- attr(*, \"label\")= chr \"Platelet count in blood at end\"\n $ end_na                          : num [1:30] 137 142 140 139 144 ...\n  ..- attr(*, \"label\")= chr \"Sodium level in serum at end\"\n $ end_k                           : num [1:30] 3.74 4.15 4.47 3.64 4.21 ...\n  ..- attr(*, \"label\")= chr \"Potassium level in serum at end\"\n $ fake_street                     : chr [1:30] \"990¬†Mohammad¬†Mountain\" \"8512¬†O'Connell¬†Valley\" \"777¬†Ledner¬†Mall\" \"690¬†Andres¬†Village\" ...\n $ fake_city                       : chr [1:30] \"North¬†Sigmundville\" \"Port¬†Halstad\" \"Croninton\" \"South¬†Isaac\" ...\n $ fake_state                      : chr [1:30] \"New¬†Mexico\" \"Missouri\" \"South¬†Carolina\" \"Montana\" ...\n $ fake_zip                        : num [1:30] 96074 11264 57246 31457 30711 ...\n $ ethnic_clean                    : Factor w/ 2 levels \"not hispanic\",..: 2 1 1 1 1 1 1 2 1 2 ...\n  ..- attr(*, \"label\")= chr \"Ethnicity\"\n $ end_na_clean                    : num [1:30] 137 142 140 139 144 ...\n  ..- attr(*, \"label\")= chr \"Sodium level in serum at end\"\n $ end_emo_clean                   : num [1:30] 32 43.2 36.9 58.7 58.9 ...\n  ..- attr(*, \"label\")= chr \"Emotional symptom score at end\"\n $ start_na_clean                  : num [1:30] 137 142 140 139 144 145 142 138 140 137 ..."
  },
  {
    "objectID": "slides/index.html#deciding-on-the-unit-of-observation",
    "href": "slides/index.html#deciding-on-the-unit-of-observation",
    "title": "Data Cleaning",
    "section": "Deciding on the Unit of Observation",
    "text": "Deciding on the Unit of Observation\n\nIn Prospective Data Collection, a patient arrives for a visit. All data collected are part of the same observation/visit.\n\nAlternatively, we can divide a visit into distinct observations, like blood pressure, a PHQ-9 depression questionnaire, and a hemoglobin measurement (all on the same date)\n\nIn retrospective data review, we can divide the observations up as we choose. For inpatient stays, we need to decide a priori on how to handle multiple observations of the same type (e.g., vitals q6h) in the same day.\n\nuse the 0800 observation each day?\nuse the daily average?\nuse the max values each day?"
  },
  {
    "objectID": "slides/index.html#what-is-the-unit-of-analysis",
    "href": "slides/index.html#what-is-the-unit-of-analysis",
    "title": "Data Cleaning",
    "section": "What is the Unit of Analysis?",
    "text": "What is the Unit of Analysis?\n\nWhile the unit of observation may be straightforward for outpatient visits, and complicated for inpatient stays, in the end we need to select a Unit of Analysis\nThis Unit of Analysis usually depends on the Question we want to ask"
  },
  {
    "objectID": "slides/index.html#is-the-unit-of-analysis-the-patient",
    "href": "slides/index.html#is-the-unit-of-analysis-the-patient",
    "title": "Data Cleaning",
    "section": "Is the Unit of Analysis the Patient?",
    "text": "Is the Unit of Analysis the Patient?\n\nDid the patient die?\nDid the patient have the outcome of colectomy?\nDid the patient reach disease remission?"
  },
  {
    "objectID": "slides/index.html#is-the-unit-of-analysis-the-visitencounter",
    "href": "slides/index.html#is-the-unit-of-analysis-the-visitencounter",
    "title": "Data Cleaning",
    "section": "Is the Unit of Analysis the Visit/Encounter?",
    "text": "Is the Unit of Analysis the Visit/Encounter?\n\nOften these are within-patient outcomes\n\nDid the C-reactive protein improve from Week 0 to Week 8?\nDid the number of sickle cell crises/year decrease after CRISPR gene therapy?\nDid the endoscopic ulcer score decrease on the experimental therapy vs placebo?"
  },
  {
    "objectID": "slides/index.html#reshaping-your-data-with-tidyr",
    "href": "slides/index.html#reshaping-your-data-with-tidyr",
    "title": "Data Cleaning",
    "section": "Reshaping your data with tidyr",
    "text": "Reshaping your data with tidyr\n\nWe often enter data by patient\nSpreadsheets encourage us to enter longitudinal data as long rows (per patient)\nWe end up with wide data\n\n[Image]"
  },
  {
    "objectID": "slides/index.html#reshaping-your-data-with-tidyr-1",
    "href": "slides/index.html#reshaping-your-data-with-tidyr-1",
    "title": "Data Cleaning",
    "section": "Reshaping your data with tidyr",
    "text": "Reshaping your data with tidyr\n\nR (and most R functions) are vectorized to handle tall data\nOne small observation per row\nLots of analyses in R are easier with tall data\n\n[Image]"
  },
  {
    "objectID": "slides/index.html#pivoting-longer-common",
    "href": "slides/index.html#pivoting-longer-common",
    "title": "Data Cleaning",
    "section": "Pivoting Longer (common)",
    "text": "Pivoting Longer (common)\n\nWe need to ‚Äòpivot‚Äô data from wide to tall on the regular\nThis ‚Äúlengthens‚Äù data, increasing the number of rows, and decreasing the number of columns\nWe will be looking at Visit Dates/Measures"
  },
  {
    "objectID": "slides/index.html#pivoting-longer",
    "href": "slides/index.html#pivoting-longer",
    "title": "Data Cleaning",
    "section": "Pivoting Longer",
    "text": "Pivoting Longer\n\nArguments: data, cols, names_to, values_to, and many optional arguments\nDetails from the tidyverse help page are here\ndata is your dataframe/tibble - you can pipe this in\ncols = columns to pivot, as a vector of names, or by number, or selected with tidyselect functions\nnames_to = A character vector specifying the new column or columns to create from the information stored in the column names of data specified by cols.\nvalues_to = A string specifying the name of the column to create from the data stored in cell values."
  },
  {
    "objectID": "slides/index.html#pivoting-longer-example",
    "href": "slides/index.html#pivoting-longer-example",
    "title": "Data Cleaning",
    "section": "Pivoting Longer (Example)",
    "text": "Pivoting Longer (Example)\nLet‚Äôs start with the wide version (selected columns from messy_uc)\n\n\n# A tibble: 30 √ó 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 001    upa               3       0      75.5    9.46      73.3    32.0\n 2 002    uste              2       1      53.6   31.6       55.7    43.2\n 3 003    oza               1       1      25.5   25.5       36.6    36.9\n 4 004    upa               3       1      79.4   35.4       80.8    58.7\n 5 005    oza               3       2      79.5   57.5       72.5    58.9\n 6 006    uste              2       1      54.5   32.5       48.3    34.6\n 7 007    uste              3       2      79.0   57.0       72.7    63.3\n 8 008    oza               3       2      79.0   57.0       74.6    65.3\n 9 009    upa               2       0      53.1    9.06      54.2    28.0\n10 010    oza               3       1      77.4   33.4       74.4    46.8\n# ‚Ñπ 20 more rows\n\n\n\nNote that there are 30 rows, one per patient, with 6 measured quantities for each patient."
  },
  {
    "objectID": "slides/index.html#pivoting-longer-example-1",
    "href": "slides/index.html#pivoting-longer-example-1",
    "title": "Data Cleaning",
    "section": "Pivoting Longer (Example)",
    "text": "Pivoting Longer (Example)\nThis is the tall version we want to end up with.\n\n\n# A tibble: 180 √ó 4\n   pat_id treatment measure   score\n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.5 \n 4 001    upa       end_bss    9.46\n 5 001    upa       start_emo 73.3 \n 6 001    upa       end_emo   32.0 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 53.6 \n10 002    uste      end_bss   31.6 \n# ‚Ñπ 170 more rows\n\n\n\nNote that there now 180 rows (30*6), with one row per observation measure."
  },
  {
    "objectID": "slides/index.html#doing-the-pivot_longer",
    "href": "slides/index.html#doing-the-pivot_longer",
    "title": "Data Cleaning",
    "section": "Doing the pivot_longer()",
    "text": "Doing the pivot_longer()\nWhat values do we want for these key arguments?\n\ncols\nnames_to\nvalues_to\n\n\n\n# A tibble: 30 √ó 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 001    upa               3       0      75.5    9.46      73.3    32.0\n 2 002    uste              2       1      53.6   31.6       55.7    43.2\n 3 003    oza               1       1      25.5   25.5       36.6    36.9\n 4 004    upa               3       1      79.4   35.4       80.8    58.7\n 5 005    oza               3       2      79.5   57.5       72.5    58.9\n 6 006    uste              2       1      54.5   32.5       48.3    34.6\n 7 007    uste              3       2      79.0   57.0       72.7    63.3\n 8 008    oza               3       2      79.0   57.0       74.6    65.3\n 9 009    upa               2       0      53.1    9.06      54.2    28.0\n10 010    oza               3       1      77.4   33.4       74.4    46.8\n# ‚Ñπ 20 more rows"
  },
  {
    "objectID": "slides/index.html#pivoting-longer-in-action",
    "href": "slides/index.html#pivoting-longer-in-action",
    "title": "Data Cleaning",
    "section": "Pivoting Longer In Action",
    "text": "Pivoting Longer In Action\n\nProblem: WideCode: pivot_longerResult: Tall\n\n\n\n\n# A tibble: 30 √ó 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 001    upa               3       0      75.5    9.46      73.3    32.0\n 2 002    uste              2       1      53.6   31.6       55.7    43.2\n 3 003    oza               1       1      25.5   25.5       36.6    36.9\n 4 004    upa               3       1      79.4   35.4       80.8    58.7\n 5 005    oza               3       2      79.5   57.5       72.5    58.9\n 6 006    uste              2       1      54.5   32.5       48.3    34.6\n 7 007    uste              3       2      79.0   57.0       72.7    63.3\n 8 008    oza               3       2      79.0   57.0       74.6    65.3\n 9 009    upa               2       0      53.1    9.06      54.2    28.0\n10 010    oza               3       1      77.4   33.4       74.4    46.8\n# ‚Ñπ 20 more rows\n\n\n\n\n\nwide |&gt; \n  pivot_longer(\n    cols = \"start_mes\":\"end_emo\", \n    # could also use 3:8\n               names_to = \"measure\",\n               values_to = \"score\")\n\n\n\n\n\n# A tibble: 180 √ó 4\n   pat_id treatment measure   score\n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.5 \n 4 001    upa       end_bss    9.46\n 5 001    upa       start_emo 73.3 \n 6 001    upa       end_emo   32.0 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 53.6 \n10 002    uste      end_bss   31.6 \n# ‚Ñπ 170 more rows"
  },
  {
    "objectID": "slides/index.html#one-minor-issue---separation-of-measure",
    "href": "slides/index.html#one-minor-issue---separation-of-measure",
    "title": "Data Cleaning",
    "section": "One Minor Issue - Separation of measure",
    "text": "One Minor Issue - Separation of measure\n\nProblemCodeResultAlternative within pivot_longer\n\n\n\nthe ‚Äúmeasure‚Äù column combines a timepoint and the measure\nNeeds to be separated.\nYou already know how to use separate()\nArguments\n\ncol\nsep\ninto\n\n\n\n\n\ntall |&gt; \n  separate(col = \"measure\",\n           sep = \"_\",\n           into = c(\"timept\", \"measure\"))\n\n\n\n\n\n# A tibble: 180 √ó 5\n   pat_id treatment timept measure score\n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;\n 1 001    upa       start  mes      3   \n 2 001    upa       end    mes      0   \n 3 001    upa       start  bss     75.5 \n 4 001    upa       end    bss      9.46\n 5 001    upa       start  emo     73.3 \n 6 001    upa       end    emo     32.0 \n 7 002    uste      start  mes      2   \n 8 002    uste      end    mes      1   \n 9 002    uste      start  bss     53.6 \n10 002    uste      end    bss     31.6 \n# ‚Ñπ 170 more rows\n\n\n\n\n\nYou can do this within pivot_longer with one more argument\n\n\nwide |&gt; \n  pivot_longer(cols = 3:8,\n    names_to = c(\"timept\", \"measure\"),\n    names_sep = \"_\",\n    values_to = \"score\")\n\n# A tibble: 180 √ó 5\n   pat_id treatment timept measure score\n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;\n 1 001    upa       start  mes      3   \n 2 001    upa       end    mes      0   \n 3 001    upa       start  bss     75.5 \n 4 001    upa       end    bss      9.46\n 5 001    upa       start  emo     73.3 \n 6 001    upa       end    emo     32.0 \n 7 002    uste      start  mes      2   \n 8 002    uste      end    mes      1   \n 9 002    uste      start  bss     53.6 \n10 002    uste      end    bss     31.6 \n# ‚Ñπ 170 more rows"
  },
  {
    "objectID": "slides/index.html#pivoting-longer-1",
    "href": "slides/index.html#pivoting-longer-1",
    "title": "Data Cleaning",
    "section": "Pivoting Longer",
    "text": "Pivoting Longer\n\nYour Turn (Exercise) with endo_data\nMeasurements of Trans-Epithelial Electrical Resistance (the inverse of leakiness) were taken from biopsies of 3 segments of intestine.\nThis might be affected by portal hypertension in patients with liver cirrhosis\n\n\n\n# A tibble: 10 √ó 5\n   pat_id portal_htn duod_teer ileal_teer colon_teer\n    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1      1          1      4.33       14.6       16.2\n 2      2          0     11.7        16.0       19.0\n 3      3          1      4.12       13.8       15.2\n 4      4          1      4.62       16.4       18.1\n 5      5          0     12.4        15.8       19.0\n 6      6          0     13.0        16.2       18.8\n 7      7          0     11.9        15.7       18.3\n 8      8          1      4.87       16.6       18.8\n 9      9          1      4.23       15.0       16.9\n10     10          0     12.8        16.7       19.1"
  },
  {
    "objectID": "slides/index.html#pivoting-longer-with-endo_data",
    "href": "slides/index.html#pivoting-longer-with-endo_data",
    "title": "Data Cleaning",
    "section": "Pivoting Longer with endo_data",
    "text": "Pivoting Longer with endo_data\n\nThe DatasetThe ArgumentsThe CodeThe Solution\n\n\n\n\n# A tibble: 10 √ó 5\n   pat_id portal_htn duod_teer ileal_teer colon_teer\n    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1      1          1      4.33       14.6       16.2\n 2      2          0     11.7        16.0       19.0\n 3      3          1      4.12       13.8       15.2\n 4      4          1      4.62       16.4       18.1\n 5      5          0     12.4        15.8       19.0\n 6      6          0     13.0        16.2       18.8\n 7      7          0     11.9        15.7       18.3\n 8      8          1      4.87       16.6       18.8\n 9      9          1      4.23       15.0       16.9\n10     10          0     12.8        16.7       19.1\n\n\n\n\n\nWhat values do you want to use for:\n\ncols\nnames_pattern = ‚Äú(.+)_teer‚Äù\nnames_to\nvalues_to\n\nNote that we are giving you the value for names_pattern, which means that we want to keep the characters of the name (of whatever length) before ‚Äú_teer‚Äù\n\n\n\n\nFill in the blanks to pivot this dataset to tall format, with columns for the intestinal location and the teer value.\nNote that we are giving you names_pattern\n\n\nendo_data |&gt; \n  pivot_longer(\n    cols =  ,\n    names_pattern = \"(.+)_teer\",\n    names_to =   ,\n    values_to = \n  )\n\n\n\n\nFill in the blanks to pivot this dataset to tall format, with columns for the intestinal location and the teer value.\n\n\nendo_data |&gt; \n  pivot_longer(\n    cols = \"duod_teer\":\"colon_teer\",\n    names_pattern = \"(.+)_teer\",\n    names_to = c(\"location\"),\n    values_to = \"teer\"\n  )\n\n\nRun the code, and look at the resulting table.\nDo you think that portal hypertension has an effect on TEER and (its inverse) epithelial leakiness?"
  },
  {
    "objectID": "slides/index.html#pivoting-wider",
    "href": "slides/index.html#pivoting-wider",
    "title": "Data Cleaning",
    "section": "Pivoting Wider",
    "text": "Pivoting Wider\n\nTall messy_uc DataCodeWider Result\n\n\n\nWide data is less common, but sometimes needed\nHere we will convert the tall version of our selected messy_uc data back to wide.\nThis is what the tall data look like\n\n\n\n# A tibble: 180 √ó 4\n   pat_id treatment measure   score\n   &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.5 \n 4 001    upa       end_bss    9.46\n 5 001    upa       start_emo 73.3 \n 6 001    upa       end_emo   32.0 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 53.6 \n10 002    uste      end_bss   31.6 \n# ‚Ñπ 170 more rows\n\n\n\n\n\ntall |&gt; \n  pivot_wider(\n    id_cols = c(pat_id, treatment), # Variables not pivoted\n    names_from = measure, # will become column names\n    values_from = score # will become values\n  )\n\n\n\n\n\n# A tibble: 30 √ó 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 001    upa               3       0      75.5    9.46      73.3    32.0\n 2 002    uste              2       1      53.6   31.6       55.7    43.2\n 3 003    oza               1       1      25.5   25.5       36.6    36.9\n 4 004    upa               3       1      79.4   35.4       80.8    58.7\n 5 005    oza               3       2      79.5   57.5       72.5    58.9\n 6 006    uste              2       1      54.5   32.5       48.3    34.6\n 7 007    uste              3       2      79.0   57.0       72.7    63.3\n 8 008    oza               3       2      79.0   57.0       74.6    65.3\n 9 009    upa               2       0      53.1    9.06      54.2    28.0\n10 010    oza               3       1      77.4   33.4       74.4    46.8\n# ‚Ñπ 20 more rows"
  },
  {
    "objectID": "slides/index.html#thickening-time-to-a-usable-level",
    "href": "slides/index.html#thickening-time-to-a-usable-level",
    "title": "Data Cleaning",
    "section": "Thickening Time to a Usable Level",
    "text": "Thickening Time to a Usable Level\n\nGoalCodeResult\n\n\n\nThe thicken function adds a column to a data frame that is of a higher interval than the original variable.\nThe variable time_stamp has the interval of seconds\nWe can thicken the data to day, or to week, or to month.\n\n\n\n\nWe will thicken to month\n\n\nemergency |&gt; \n  thicken('month')\n\n\n\n\nThis lets us count events like overdoses by month with time_stamp_month.\n\n\n\n# A tibble: 120,450 √ó 7\n     lat   lng   zip title            time_stamp          twp   time_stamp_month\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;            &lt;dttm&gt;              &lt;chr&gt; &lt;date&gt;          \n 1  40.3 -75.6 19525 EMS: BACK PAINS‚Ä¶ 2015-12-10 17:40:00 NEW ‚Ä¶ 2015-12-01      \n 2  40.3 -75.3 19446 EMS: DIABETIC E‚Ä¶ 2015-12-10 17:40:00 HATF‚Ä¶ 2015-12-01      \n 3  40.1 -75.4 19401 Fire: GAS-ODOR/‚Ä¶ 2015-12-10 17:40:00 NORR‚Ä¶ 2015-12-01      \n 4  40.1 -75.3 19401 EMS: CARDIAC EM‚Ä¶ 2015-12-10 17:40:01 NORR‚Ä¶ 2015-12-01      \n 5  40.3 -75.6    NA EMS: DIZZINESS   2015-12-10 17:40:01 LOWE‚Ä¶ 2015-12-01      \n 6  40.3 -75.3 19446 EMS: HEAD INJURY 2015-12-10 17:40:01 LANS‚Ä¶ 2015-12-01      \n 7  40.2 -75.1 19044 EMS: NAUSEA/VOM‚Ä¶ 2015-12-10 17:40:01 HORS‚Ä¶ 2015-12-01      \n 8  40.2 -75.4 19426 EMS: RESPIRATOR‚Ä¶ 2015-12-10 17:40:01 SKIP‚Ä¶ 2015-12-01      \n 9  40.3 -75.4 19438 EMS: SYNCOPAL E‚Ä¶ 2015-12-10 17:40:01 LOWE‚Ä¶ 2015-12-01      \n10  40.1 -75.3 19462 Traffic: VEHICL‚Ä¶ 2015-12-10 17:40:01 PLYM‚Ä¶ 2015-12-01      \n# ‚Ñπ 120,440 more rows"
  },
  {
    "objectID": "slides/index.html#padding-unobserved-dates-weekends",
    "href": "slides/index.html#padding-unobserved-dates-weekends",
    "title": "Data Cleaning",
    "section": "Padding unobserved dates (weekends?)",
    "text": "Padding unobserved dates (weekends?)\n\n\n\nThe pad function allows you to fill in missing intervals.\nAs an example, my hospital only runs fecal calprotectin tests on weekdays.\nThis can lead to weird discontinuities in data over a weekend (Dec 3-4).\nNo observations on weekend days.\n\n\n\n\n# A tibble: 15 √ó 3\n   pat_id date         fcp\n   &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt;\n 1 001    2022-12-01  1574\n 2 001    2022-12-02  1323\n 3 001    2022-12-05   673\n 4 001    2022-12-06   314\n 5 001    2022-12-07   168\n 6 002    2022-11-30  1393\n 7 002    2022-12-01  1014\n 8 002    2022-12-02   812\n 9 002    2022-12-05   247\n10 002    2022-12-06   118\n11 003    2022-12-02   987\n12 003    2022-12-05   438\n13 003    2022-12-06   312\n14 003    2022-12-05   194\n15 003    2022-12-06   101"
  },
  {
    "objectID": "slides/index.html#padding-unobserved-times",
    "href": "slides/index.html#padding-unobserved-times",
    "title": "Data Cleaning",
    "section": "Padding Unobserved Times",
    "text": "Padding Unobserved Times\n\nThe ProblemThe CodeThe Result\n\n\n\nWe can fill in (pad) the unobserved weekend days with the pad() function.\n\n\n\n\nfcp |&gt; \n  pad(group = \"pat_id\") |&gt; \n  tidyr::fill(pat_id) |&gt; \n  print(n = 14)\n\n\n\n\n\n\n\n# A tibble: 21 √ó 3\n   pat_id date         fcp\n   &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt;\n 1 001    2022-12-01  1574\n 2 001    2022-12-02  1323\n 3 001    2022-12-03    NA\n 4 001    2022-12-04    NA\n 5 001    2022-12-05   673\n 6 001    2022-12-06   314\n 7 001    2022-12-07   168\n 8 002    2022-11-30  1393\n 9 002    2022-12-01  1014\n10 002    2022-12-02   812\n11 002    2022-12-03    NA\n12 002    2022-12-04    NA\n13 002    2022-12-05   247\n14 002    2022-12-06   118\n# ‚Ñπ 7 more rows\n\n\n\n\nNew observations are created on the missing dates\nNAs are filled in for the missing FCPs, with one for each day and group (pat_id)\nwe used tidyr::fill(pat_id) to fill in the missing pat_ids"
  },
  {
    "objectID": "slides/index.html#joins-of-data-from-different-sources",
    "href": "slides/index.html#joins-of-data-from-different-sources",
    "title": "Data Cleaning",
    "section": "Joins of data from different sources",
    "text": "Joins of data from different sources\n\nWe often collect data from different sources that we later want to join together for analysis\n\nData from local Electronic Medical Record\nData from the CDC\nData from the US Census\n\nExternal data can illuminate our understanding of our local patient data"
  },
  {
    "objectID": "slides/index.html#local-demographics-with-cdc-svi-data",
    "href": "slides/index.html#local-demographics-with-cdc-svi-data",
    "title": "Data Cleaning",
    "section": "Local Demographics with CDC SVI data",
    "text": "Local Demographics with CDC SVI data\n\nThe ProblemThe CodeThe Result\n\n\n\n\n\nWe have 2 datasets, one local Demographics and Census Tract, and one from the CDC that has values for Social Vulnerability Index by Census Tract\nWe want to know the median SVI for the neighborhood of each patient\nWe need to left_join these datasets together by matching on the Census Tract\n\n\n\n\n\nJoins"
  },
  {
    "objectID": "slides/index.html#patient-demographics-with-lab-results-one-to-many",
    "href": "slides/index.html#patient-demographics-with-lab-results-one-to-many",
    "title": "Data Cleaning",
    "section": "Patient Demographics with Lab results (one to many)",
    "text": "Patient Demographics with Lab results (one to many)"
  },
  {
    "objectID": "slides/index.html#thank-you",
    "href": "slides/index.html#thank-you",
    "title": "Data Cleaning",
    "section": "Thank you!",
    "text": "Thank you!\nüôè Click here to submit workshop feedback\n\n\n\nData Cleaning"
  },
  {
    "objectID": "slidespage.html",
    "href": "slidespage.html",
    "title": "Slides",
    "section": "",
    "text": "View slides in full screen"
  }
]